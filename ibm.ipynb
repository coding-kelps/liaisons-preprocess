{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# liaisons-preprocess - IBM's Claim Stance Dataset\n",
    "\n",
    "This notebook outlines the preprocessing steps undertaken to generate datasets used for testing the [liaisons](https://github.com/coding-kelps/liaisons) client and [benchmarking open-source models in predicting argument relations](https://github.com/coding-kelps/liaisons-experiments).\n",
    "\n",
    "## About the Dataset\n",
    "\n",
    "For this preprocessing task, we utilized IBM's \"Claim Stance Dataset\" as the source, a dataset of claims over controversial topics, collected from Wikipedia. Each claim is labeled based on its stance towards the topic, either \"PRO\" (supporting the topic) or \"CON\" (opposing the topic), making it an excellent resource for relation-based argument mining tasks.\n",
    "\n",
    "As of now, the dataset is available on [HuggingFace](https://huggingface.co/datasets/ibm/claim_stance). Further details on the original dataset can be found in the paper *Stance Classification of Context-Dependent Claims* (Bar-Haim et al., 2017).\n",
    "\n",
    "## About the Preprocessing\n",
    "\n",
    "The primary aim of this preprocessing is to create representative samples of the dataset, roughly 100 entries, enabling benchmarking with limited computing resources. Secondly, previous models in the field of relation-based argument mining have proven to give misleading benchmarks by achieving satisfactory results in specific domains (Gorur et al., 2024). To circumvent this, the preprocessing will also modify the distribution of claims to achieve a balanced plurality of stances and topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset from HuggingFace (https://huggingface.co/datasets/ibm/claim_stance)\n",
    "ds = load_dataset(\"ibm/claim_stance\", \"claim_stance\")\n",
    "\n",
    "# Combine \"train\" and \"test\" datasets as no training\n",
    "# will be conducted over this source\n",
    "df = pd.concat([ds[\"train\"].to_pandas(), ds[\"test\"].to_pandas()]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Properties\n",
    "\n",
    "The dataset features 2,394 labeled claims across 55 controversial topics. While the distribution of claim stances over the dataset is mostly equal (~55% PRO, ~45% CON), the distribution of topics being discussed is quite unbalanced. For example, the \"unleash the free market\" topic represents ~8% of the claims by itself. Also, claim stances are binary as they can only support or attack the related topic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\"\"\"\n",
    "    Plot the dataset distribution of stances over claim\n",
    "\"\"\"\n",
    "\n",
    "# Calculate value distribution proportions of the \"claims.stance\" column\n",
    "proportions = df[\"claims.stance\"].value_counts(normalize=True)\n",
    "\n",
    "# Plotting the distribution\n",
    "sns.barplot(x=proportions.index, y=proportions.values)\n",
    "plt.title(\"Proportional distribution of stances over claim\")\n",
    "plt.xlabel(\"Stance\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Plot the dataset distribution of topics over claim\n",
    "\"\"\"\n",
    "\n",
    "# Calculate value distribution proportions of the \"topicTarget\" column\n",
    "proportions = df[\"topicTarget\"].value_counts(normalize=True)\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "ax = sns.barplot(x=proportions.index, y=proportions.values)\n",
    "plt.title(\"Proportional distribution of topics over claim\")\n",
    "plt.xlabel(\"Topic\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "# Fix ticks position to avoid hazardous position\n",
    "# https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.set_xticklabels.html\n",
    "ax.set_xticks(ax.get_xticks())\n",
    "# Rotate labels and align to the right\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "# Adjust layout to ensure everything fits without overlap\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing notes\n",
    "\n",
    "The preprocessing focus on the making of two samples:\n",
    "- a **binary** sample which doesn't change the possible stance (or relation) a claim can have to a topic (either PRO or CON).\n",
    "- a **ternary** sample which introduce a new *unrelated* value through rule-based data augmentation. New entries are generated by taking claims and associating them to topics deemed unrelated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Dataset preprocessing for binary sample (with PRO/CON stances) \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Compute the counts of each combination of 'claims.stance' and 'topicTarget'\n",
    "combination_counts = df.groupby(['claims.stance', 'topicTarget']).size()\n",
    "\n",
    "# Calculate the number of unique combinations\n",
    "num_combinations = len(combination_counts)\n",
    "\n",
    "# Make the sample about a hundred elements\n",
    "# Take the number of combinations if it is greater than 100 to avoid empty dataset\n",
    "sample_nb_entries = max(100, num_combinations)\n",
    "\n",
    "# Compute the number of entries per combination to get roughly 100 entries in total\n",
    "# Ensure that it's not greater than the minimum count among the combinations\n",
    "entries_per_combination = min(int(sample_nb_entries / num_combinations), combination_counts.min())\n",
    "\n",
    "binary_sampled_df = df.groupby(['claims.stance', 'topicTarget'], group_keys=False).apply(\n",
    "    lambda x: x.sample(entries_per_combination, replace=True)\n",
    ").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Generate \"UNRELATED\" claims to topic through rule-based data augmentation\n",
    "\"\"\"\n",
    "\n",
    "# These unrelated topics have been arbitrary selected\n",
    "# and can be prone to debate.\n",
    "unrelated_topics = [\n",
    "    (\"have children\", \"boxing\"),\n",
    "    (\"governments should choose open source software\", \"re-engage with Myanmar\"),\n",
    "    (\"the sale of violent video games to minors\", \"build hydroelectric dams\"),\n",
    "    (\"the use of performance enhancing drugs in professional sports\", \"Holocaust denial\"),\n",
    "    (\"the one-child policy of the republic of China\", \"intellectual property rights\"),\n",
    "    (\"atheism\", \"wind power\"),\n",
    "    (\"the monarchy\", \"raising the school leaving age to 18\"),\n",
    "    (\"endangered species\", \"freedom of speech\"),\n",
    "    (\"advertising\", \"the blockade of Gaza\"),\n",
    "    (\"only teach abstinence for sex education in schools\", \"the right to bear arms\"),\n",
    "    (\"gambling\", \"all nations have a right to nuclear weapons\"),\n",
    "    (\"leaking of military documents\", \"austerity measures\")\n",
    "]\n",
    "\n",
    "# The number of generated entries to make through data augmentation\n",
    "nb_generated = 3\n",
    "\n",
    "unrelated_claims_df = pd.DataFrame()\n",
    "\n",
    "for topic_a, topic_b in unrelated_topics:\n",
    "    matched_rows_a = df[df[\"topicTarget\"] == topic_a]\n",
    "    matched_rows_b = df[df[\"topicTarget\"] == topic_b]\n",
    "\n",
    "    if matched_rows_a.shape[0] >= nb_generated and matched_rows_b.shape[0] >= nb_generated:\n",
    "        topic_a_sample = matched_rows_a.sample(n=nb_generated).reset_index(drop=True)\n",
    "        topic_b_sample = matched_rows_b.sample(n=nb_generated).reset_index(drop=True)\n",
    "\n",
    "        topic_a_sample[[\"topicTarget\", \"topicText\"]], topic_b_sample[[\"topicTarget\", \"topicText\"]] = \\\n",
    "            topic_b_sample[[\"topicTarget\", \"topicText\"]], topic_a_sample[[\"topicTarget\", \"topicText\"]]\n",
    "\n",
    "        unrelated_claims_df = pd.concat([unrelated_claims_df, topic_a_sample, topic_b_sample], ignore_index=True)        \n",
    "\n",
    "# Set claims stance for all generated entries to \"UNRELATED\"\n",
    "unrelated_claims_df[\"claims.stance\"] = \"UNRELATED\"\n",
    "\n",
    "# Concat back the generated entries to the original dataset\n",
    "data_augmented_df = pd.concat([df, unrelated_claims_df], ignore_index=True)\n",
    "\n",
    "# Retrieve all the topics which haven't been augmented for the \"UNRELATED\" claim stance\n",
    "valid_topic_targets = data_augmented_df[data_augmented_df['claims.stance'] == 'UNRELATED']['topicTarget'].unique()\n",
    "\n",
    "# Remove all unaugmented topics to ensure that the dataset is balanced\n",
    "data_augmented_df = data_augmented_df[data_augmented_df['topicTarget'].isin(valid_topic_targets)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Dataset preprocessing for ternary sample (with PRO/CON/UNRELATED stances) \n",
    "\"\"\"\n",
    "\n",
    "# Compute the counts of each combination of 'claims.stance' and 'topicTarget'\n",
    "combination_counts = data_augmented_df.groupby(['claims.stance', 'topicTarget']).size()\n",
    "\n",
    "# Calculate the number of unique combinations\n",
    "num_combinations = len(combination_counts)\n",
    "\n",
    "# Make the sample about a hundred elements\n",
    "# Take the number of combinations if it is greater than 100 to avoid empty dataset\n",
    "sample_nb_entries = max(100, num_combinations)\n",
    "\n",
    "# Compute the number of entries per combination to get roughly 100 entries in total\n",
    "# Ensure that it's not greater than the minimum count among the combinations\n",
    "entries_per_combination = min(int(sample_nb_entries / num_combinations), combination_counts.min())\n",
    "\n",
    "ternary_sampled_df = data_augmented_df.groupby(['claims.stance', 'topicTarget'], group_keys=False).apply(\n",
    "    lambda x: x.sample(entries_per_combination, replace=True)\n",
    ").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Results Notes\n",
    "\n",
    "The distribution of 'claims.stance' and 'topicTarget' has been rebalanced to achieve equal frequency across categories. However, it is important to note that the data augmentation used to generate unrelated claims has resulted in a reduction in the diversity of topics within the ternary sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Plot the binary and ternary samples distribution of stances over claim\n",
    "\"\"\"\n",
    "\n",
    "# Calculate value distribution proportions of the \"claims.stance\" column\n",
    "bin_proportions = binary_sampled_df[\"claims.stance\"].value_counts(normalize=True)\n",
    "\n",
    "# Calculate value distribution proportions of the \"claims.stance\" column\n",
    "ter_proportions = ternary_sampled_df[\"claims.stance\"].value_counts(normalize=True)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5), sharey=True)\n",
    "fig.suptitle('Proportional distribution of stances over claim')\n",
    "\n",
    "# Plotting the distribution\n",
    "sns.barplot(ax=axes[0], x=bin_proportions.index, y=bin_proportions.values)\n",
    "axes[0].set_title(\"Binary Sample\")\n",
    "axes[0].set_xlabel(\"Stance\")\n",
    "axes[0].set_ylabel(\"Frequency\")\n",
    "\n",
    "# Plotting the distribution\n",
    "sns.barplot(ax=axes[1], x=ter_proportions.index, y=ter_proportions.values)\n",
    "axes[1].set_title(\"Ternary Sample\")\n",
    "axes[1].set_xlabel(\"Stance\")\n",
    "axes[1].set_ylabel(\"Frequency\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Plot the binary sample distribution of topics over claim\n",
    "\"\"\"\n",
    "\n",
    "# Calculate value distribution proportions of the \"topicTarget\" column\n",
    "proportions = binary_sampled_df[\"topicTarget\"].value_counts(normalize=True)\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "ax = sns.barplot(x=proportions.index, y=proportions.values)\n",
    "plt.title(\"Proportional distribution of topics over claim in binary sample\")\n",
    "plt.xlabel(\"Topic\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "# Fix ticks position to avoid hazardous position\n",
    "# https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.set_xticklabels.html\n",
    "ax.set_xticks(ax.get_xticks())\n",
    "# Rotate labels and align to the right\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "# Adjust layout to ensure everything fits without overlap\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Plot the ternary sample distribution of topics over claim\n",
    "\"\"\"\n",
    "\n",
    "# Calculate value distribution proportions of the \"topicTarget\" column\n",
    "proportions = ternary_sampled_df[\"topicTarget\"].value_counts(normalize=True)\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "ax = sns.barplot(x=proportions.index, y=proportions.values)\n",
    "plt.title(\"Proportional distribution of topics over claim in ternary sample\")\n",
    "plt.xlabel(\"Topic\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "# Fix ticks position to avoid hazardous position\n",
    "# https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.set_xticklabels.html\n",
    "ax.set_xticks(ax.get_xticks())\n",
    "# Rotate labels and align to the right\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "# Adjust layout to ensure everything fits without overlap\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Samples\n",
    "\n",
    "Finally, for the dataset to be used in further experiments, both samples need to be cleaned by removing the now useless columns and renaming the remaining columns to fit the template of the [experiment framework](https://github.com/coding-kelps/liaisons-experiments)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Clean dataset to follow expected template for benchmarking\n",
    "\"\"\"\n",
    "\n",
    "# Extract essentials column for argument relation prediction task\n",
    "binary_clean_df = binary_sampled_df.loc[:, [\"topicText\", \"claims.claimCorrectedText\", \"claims.stance\"]]\n",
    "\n",
    "# Rename column to fit to liaisons-experiments data template\n",
    "binary_clean_df = binary_clean_df.rename(columns={\"topicText\": \"parent_argument\", \"claims.claimCorrectedText\": \"child_argument\", \"claims.stance\": \"relation\"})\n",
    "\n",
    "# Rename relation value categories\n",
    "binary_clean_df['relation'] = binary_clean_df['relation'].replace({\"PRO\": \"support\", \"CON\": \"attack\"})\n",
    "\n",
    "binary_clean_df = binary_clean_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Clean dataset to follow expected template for benchmarking\n",
    "\"\"\"\n",
    "\n",
    "# Extract essentials column for argument relation prediction task\n",
    "ternary_clean_df = ternary_sampled_df.loc[:, [\"topicText\", \"claims.claimCorrectedText\", \"claims.stance\"]]\n",
    "\n",
    "# Rename column to fit to liaisons-experiments data template\n",
    "ternary_clean_df = ternary_clean_df.rename(columns={\"topicText\": \"parent_argument\", \"claims.claimCorrectedText\": \"child_argument\", \"claims.stance\": \"relation\"})\n",
    "\n",
    "# Rename relation value categories\n",
    "ternary_clean_df['relation'] = ternary_clean_df['relation'].replace({\"PRO\": \"support\", \"CON\": \"attack\", \"UNRELATED\": \"unrelated\"})\n",
    "\n",
    "ternary_clean_df = ternary_clean_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Push datasets to HuggingFace\n",
    "\"\"\"\n",
    "\n",
    "from datasets import Dataset, DatasetDict\n",
    "import os\n",
    "\n",
    "# Load pd.DataFrame as Dataset\n",
    "binary_data = Dataset.from_pandas(binary_clean_df)\n",
    "ternary_data = Dataset.from_pandas(ternary_clean_df)\n",
    "\n",
    "# Sum up all generated datasets into a single DatasetDict\n",
    "dataset = DatasetDict({\n",
    "    'binary': binary_data,\n",
    "    'ternary': ternary_data\n",
    "})\n",
    "\n",
    "hf_token = os.environ.get(\"LIAISONS_HUGGING_FACE_TOKEN\")\n",
    "\n",
    "# Then push to HuggingFace Repository\n",
    "dataset.push_to_hub('coding-kelps/liaisons-ibm-debater-claim-stance', token=hf_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliography\n",
    "- Bar-Haim, R., Bhattacharya, I., Dinuzzo, F., Saha, A., and Slonim, N. (2017). Stance classification of context dependent claims. In Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 1, Long Papers, pages 251–261.\n",
    "- Gorur, D., Rago, A. and Toni, F. (2024). Can Large Language Models perform Relation-based Argument Mining? [online] arXiv.org. doi:https://doi.org/10.48550/arXiv.2402.11243."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
